request:
  model: gemini-1.5-pro
  contents:
    - role: user
      parts:
        - text: "Extract information from this resume:\n\n${resume_text}"
  settings:
    generation_config:
      max_output_tokens: 1024
      temperature: 0.7
      top_p: 0.9
      top_k: 40
      presence_penalty: 0.0
      frequency_penalty: 0.0
      stop_sequences:
        - "###"

model: gemini-1.5-pro
provider: Google
version: 0.1.0
